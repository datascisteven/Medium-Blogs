{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('nlp-env': conda)"
  },
  "interpreter": {
   "hash": "64843a974ef730d2a1ddea12a7b62262ac10d807767ccbfe47ff1f82cf3cbab5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importing Packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0f/dj_hz1316w7c4qhdk33w3p3w0000gn/T/ipykernel_19329/1618558760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/My Seagate Demidrive/Dropbox/Data Science/VSCode/Repositories/Medium-Blogs/py/preprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages/gensim/corpora/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[0;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages/gensim/corpora/indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;31m# try to load fast, cythonized code if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.8/site-packages/gensim/_matutils.pyx\u001b[0m in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import gensim\n",
    "from textblob import Word\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"py/\")\n",
    "from utils import *\n",
    "from config import keys\n",
    "from preprocess import *\n"
   ]
  },
  {
   "source": [
    "# Davidson Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>hate_speech</th>\n      <th>offensive_language</th>\n      <th>neither</th>\n      <th>class</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/hate_tweet/labeled_data.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df = df.drop(columns=['count', 'hate_speech', 'offensive_language', 'neither'], axis=1)\n",
    "df.columns = ['label', 'text']\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    23353\n",
       "1     1430\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "df = df.replace({'label': {1: 0, 2: 0, 0: 1}})\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label                                               text\n",
       "0      0  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1      0  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2      0  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3      0  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4      0  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "# Aristotle Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             tweet_id maj_label\n",
       "0  849667487180259329   abusive\n",
       "1  850490912954351616   abusive\n",
       "2  848791766853668864   abusive\n",
       "3  848306464892604416   abusive\n",
       "4  850010509969465344    normal"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>maj_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>849667487180259329</td>\n      <td>abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>850490912954351616</td>\n      <td>abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>848791766853668864</td>\n      <td>abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>848306464892604416</td>\n      <td>abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850010509969465344</td>\n      <td>normal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/hate_tweet/hatespeechtwitter.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/2/tweets?ids=847661947159891972,847799130277675008,848933211375779840&tweet.fields=created_at,entities,geo,id,public_metrics,text&user.fields=description,entities,id,location,name,public_metrics,username\"\n",
    "payload={}\n",
    "headers = {'Authorization': 'Bearer ' + keys['bearer_token'], 'Cookie': 'personalization_id=\"v1_hzpv7qXpjB6CteyAHDWYQQ==\"; guest_id=v1%3A161498381400435837'}\n",
    "r = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "normal     52835\n",
       "spam       13404\n",
       "abusive    10122\n",
       "hateful     3635\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df2.columns = ['id', 'label']\n",
    "df2.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hateful = df2[df2['label']=='hateful']\n",
    "hate_ids = group_list(list(df_hateful.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 37/37 [00:24<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df_hate = tweets_request(hate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hate = df_hate.reset_index(drop=True)\n",
    "pickle.dump(df_hate, open(\"data/pickle/aristotle_hate.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  I hate er chase because if the Bitch that work...      1\n",
       "1  RT @nyctophil3: Pineapples do not belong on pi...      1\n",
       "2  Niggas keep talking about women wearing weave ...      1\n",
       "3  @vappywave idiot that's not gonna work. you go...      1\n",
       "4  RT @ayevonnn: bruh i fucking hate people like ...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I hate er chase because if the Bitch that work...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RT @nyctophil3: Pineapples do not belong on pi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Niggas keep talking about women wearing weave ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@vappywave idiot that's not gonna work. you go...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @ayevonnn: bruh i fucking hate people like ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "df_2 = pickle.load(open(\"data/pickle/aristotle_hate.pickle\", \"rb\"))\n",
    "df_2['label'] = 1\n",
    "df_2 = df_2[['text', 'label']]\n",
    "df_2.head()"
   ]
  },
  {
   "source": [
    "# University of Copenhagen Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   572342978255048705  racism\n",
       "0  572341498827522049  racism\n",
       "1  572340476503724032  racism\n",
       "2  572334712804384768  racism\n",
       "3  572332655397629952  racism\n",
       "4  575949086055997440  racism"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>572342978255048705</th>\n      <th>racism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>572341498827522049</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>572340476503724032</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>572334712804384768</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>572332655397629952</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>575949086055997440</td>\n      <td>racism</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df3 = pd.read_csv('data/hate_tweet/NAACL_SRW_2016.csv')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "none      11559\n",
       "sexism     3378\n",
       "racism     1969\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df3.columns = ['id', 'label']\n",
    "df3.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 54/54 [00:29<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "df_racsex = df3[(df3['label']=='racism') | (df3['label']=='sexism')]\n",
    "racsex_id = group_list(list(df_racsex.id))\n",
    "df_rac_sex = tweets_request(racsex_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rac_sex = df_rac_sex.reset_index(drop=True)\n",
    "pickle.dump(df_rac_sex, open(\"data/pickle/copenhagen.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  Drasko they didn't cook half a bird you idiot ...      1\n",
       "1  Hopefully someone cooks Drasko in the next ep ...      1\n",
       "2  of course you were born in serbia...you're as ...      1\n",
       "3  These girls are the equivalent of the irritati...      1\n",
       "4  RT @YesYoureRacist: At least you're only a tin...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>of course you were born in serbia...you're as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>These girls are the equivalent of the irritati...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @YesYoureRacist: At least you're only a tin...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "df_3 = pickle.load(open(\"data/pickle/copenhagen.pickle\", \"rb\"))\n",
    "df_3['label'] = 1\n",
    "df_3 = df_3[['text', 'label']]\n",
    "df_3.head()"
   ]
  },
  {
   "source": [
    "# HASOC Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      text_id                                               text task_1  \\\n",
       "0  hasoc_en_1  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   \n",
       "1  hasoc_en_2  @politico No. We should remember very clearly ...    HOF   \n",
       "2  hasoc_en_3  @cricketworldcup Guess who would be the winner...    NOT   \n",
       "3  hasoc_en_4  Corbyn is too politically intellectual for #Bo...    NOT   \n",
       "4  hasoc_en_5  All the best to #TeamIndia for another swimmin...    NOT   \n",
       "\n",
       "  task_2 task_3  \n",
       "0   NONE   NONE  \n",
       "1   HATE    TIN  \n",
       "2   NONE   NONE  \n",
       "3   NONE   NONE  \n",
       "4   NONE   NONE  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>text</th>\n      <th>task_1</th>\n      <th>task_2</th>\n      <th>task_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hasoc_en_1</td>\n      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n      <td>NOT</td>\n      <td>NONE</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hasoc_en_2</td>\n      <td>@politico No. We should remember very clearly ...</td>\n      <td>HOF</td>\n      <td>HATE</td>\n      <td>TIN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hasoc_en_3</td>\n      <td>@cricketworldcup Guess who would be the winner...</td>\n      <td>NOT</td>\n      <td>NONE</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hasoc_en_4</td>\n      <td>Corbyn is too politically intellectual for #Bo...</td>\n      <td>NOT</td>\n      <td>NONE</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hasoc_en_5</td>\n      <td>All the best to #TeamIndia for another swimmin...</td>\n      <td>NOT</td>\n      <td>NONE</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data/hate_tweet/english_dataset.tsv\", delimiter = \"\\t\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  #DhoniKeepsTheGlove | WATCH: Sports Minister K...      1\n",
       "1  @politico No. We should remember very clearly ...      1\n",
       "2  @cricketworldcup Guess who would be the winner...      1\n",
       "3  Corbyn is too politically intellectual for #Bo...      1\n",
       "4  All the best to #TeamIndia for another swimmin...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@politico No. We should remember very clearly ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@cricketworldcup Guess who would be the winner...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Corbyn is too politically intellectual for #Bo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>All the best to #TeamIndia for another swimmin...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "hasoc_hate = df4[df4.task_2 == 'HATE']\n",
    "df4['label'] = 1\n",
    "df4 = df4[['text', 'label']]\n",
    "df4.head()"
   ]
  },
  {
   "source": [
    "# Combined Dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    23353\n",
       "1    11736\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "combined = pd.concat([df, df_2, df_3, df4], ignore_index=True)\n",
    "combined.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0f/dj_hz1316w7c4qhdk33w3p3w0000gn/T/ipykernel_19329/3554413945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_not_hate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_hate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_hate_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hate_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hate_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hate_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_hate_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hate_tt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hate_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hate_tt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hate_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hate_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_not_hate_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_not_hate_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_not_hate_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_not_hate_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_not_hate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_not_hate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "hate = combined[combined.label == 1]\n",
    "not_hate = combined[combined.label == 0]\n",
    "\n",
    "X_hate = hate.text\n",
    "y_hate = hate.label\n",
    "X_not_hate = not_hate.text\n",
    "y_not_hate = not_hate.label\n",
    "\n",
    "X_hate_tr, X_hate_val, y_hate_tr, y_hate_val = train_test_split(X_hate, y_hate, test_size=0.25, random_state=42)\n",
    "X_hate_val, X_hate_tt, y_hate_val, y_hate_tt = train_test_split(X_hate_val, y_hate_val, test_size=0.4, random_state=42)\n",
    "X_not_hate_tr, X_not_hate_val, y_not_hate_tr, y_not_hate_val = train_test_split(X_not_hate, y_not_hate, test_size=0.25, random_state=42)\n",
    "X_not_hate_val, X_not_hate_tt, y_not_hate_val, y_not_hate_tt = train_test_split(X_not_hate_val, y_not_hate_val, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}