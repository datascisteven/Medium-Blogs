{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('learn-env': conda)"
  },
  "interpreter": {
   "hash": "80773cdecc613a186b9eac051636553d2ff0f99c57590601666ed713bd5d0256"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importing Packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-14 07:29:33,658:DEBUG:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "\n",
    "import smote_variants as sv\n",
    "import imbalanced_databases as imbd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict, GridSearchCV,RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, classification_report, plot_confusion_matrix, mean_squared_error, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, NearMiss, OneSidedSelection, NeighbourhoodCleaningRule, RandomUnderSampler, TomekLinks, EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, SVMSMOTE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier, RUSBoostClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "source": [
    "# Importing Training and Validation Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"data/training_cleaned.pickle\", \"rb\")\n",
    "train = pickle.load(pickle_in)\n",
    "pickle_in = open(\"data/validate_cleaned.pickle\", \"rb\")\n",
    "validate = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"default\"], axis=1)\n",
    "y_train = train[\"default\"]\n",
    "X_valid = validate.drop([\"default\"], axis=1)\n",
    "y_valid = validate[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     limit  gender  education  marriage  age  behind1  behind2  behind3  \\\n",
       "0  1790.26       2          2         1   44        0        0        0   \n",
       "1  5728.83       2          3         1   46       -1       -1       -1   \n",
       "2  3580.52       2          2         1   47       -1       -1       -1   \n",
       "3  6086.88       2          2         1   29        0        0        0   \n",
       "4  5370.78       2          1         2   33       -2       -2       -2   \n",
       "\n",
       "   behind4  behind5  ...  billed3  billed4  billed5  billed6   paid1    paid2  \\\n",
       "0        0        0  ...  1278.35   800.60   847.12   981.81  107.99   179.13   \n",
       "1        0       -1  ...   173.87   147.77   143.04    30.15   83.89   173.87   \n",
       "2       -1       -1  ...     0.00   224.50   -14.18   -14.18  238.68     0.00   \n",
       "3        0        0  ...  2267.08  2288.06  1557.71  1575.25   80.02    89.26   \n",
       "4       -2       -2  ...  1170.90  1198.01   995.38    80.96  966.99  1171.37   \n",
       "\n",
       "     paid3   paid4   paid5    paid6  \n",
       "0   107.42  107.42  179.03    33.08  \n",
       "1    35.81  143.04   30.15   942.14  \n",
       "2   224.50    0.00    0.00     0.00  \n",
       "3    92.56   60.26   68.07    75.58  \n",
       "4  1198.58  995.67   80.96  6067.73  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>limit</th>\n      <th>gender</th>\n      <th>education</th>\n      <th>marriage</th>\n      <th>age</th>\n      <th>behind1</th>\n      <th>behind2</th>\n      <th>behind3</th>\n      <th>behind4</th>\n      <th>behind5</th>\n      <th>...</th>\n      <th>billed3</th>\n      <th>billed4</th>\n      <th>billed5</th>\n      <th>billed6</th>\n      <th>paid1</th>\n      <th>paid2</th>\n      <th>paid3</th>\n      <th>paid4</th>\n      <th>paid5</th>\n      <th>paid6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1790.26</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1278.35</td>\n      <td>800.60</td>\n      <td>847.12</td>\n      <td>981.81</td>\n      <td>107.99</td>\n      <td>179.13</td>\n      <td>107.42</td>\n      <td>107.42</td>\n      <td>179.03</td>\n      <td>33.08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5728.83</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>46</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>...</td>\n      <td>173.87</td>\n      <td>147.77</td>\n      <td>143.04</td>\n      <td>30.15</td>\n      <td>83.89</td>\n      <td>173.87</td>\n      <td>35.81</td>\n      <td>143.04</td>\n      <td>30.15</td>\n      <td>942.14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3580.52</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>47</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>224.50</td>\n      <td>-14.18</td>\n      <td>-14.18</td>\n      <td>238.68</td>\n      <td>0.00</td>\n      <td>224.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6086.88</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2267.08</td>\n      <td>2288.06</td>\n      <td>1557.71</td>\n      <td>1575.25</td>\n      <td>80.02</td>\n      <td>89.26</td>\n      <td>92.56</td>\n      <td>60.26</td>\n      <td>68.07</td>\n      <td>75.58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5370.78</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>33</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>...</td>\n      <td>1170.90</td>\n      <td>1198.01</td>\n      <td>995.38</td>\n      <td>80.96</td>\n      <td>966.99</td>\n      <td>1171.37</td>\n      <td>1198.58</td>\n      <td>995.67</td>\n      <td>80.96</td>\n      <td>6067.73</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     limit  gender  education  marriage  age  behind1  behind2  behind3  \\\n",
       "0  1074.16       1          2         2   25        0        0        0   \n",
       "1  5370.78       2          1         2   26        0        0        0   \n",
       "2  2506.36       2          3         1   32        0        0        0   \n",
       "3  4654.68       1          3         2   49        0        0        0   \n",
       "4  1790.26       2          2         2   36        0        0        0   \n",
       "\n",
       "   behind4  behind5  ...  billed3  billed4  billed5  billed6   paid1   paid2  \\\n",
       "0        0        0  ...   414.66   450.43   491.10   530.92   53.71   71.61   \n",
       "1        0        0  ...  4177.89  3637.13  2783.53  2766.45  160.62  151.64   \n",
       "2        0        0  ...  2453.73  2497.52  2510.34  2513.96   87.04  111.43   \n",
       "3        0        0  ...   579.04   605.04   402.31   248.63   57.65   64.74   \n",
       "4        0        0  ...  1516.74   700.85   726.67   696.02   71.61   53.71   \n",
       "\n",
       "    paid3  paid4   paid5   paid6  \n",
       "0   53.71  53.71   53.71   71.61  \n",
       "1  113.18  94.78   95.56   95.56  \n",
       "2  107.42  87.29   89.51   91.45  \n",
       "3  251.14   0.97  251.03  157.83  \n",
       "4   35.81  64.45    0.00   35.81  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>limit</th>\n      <th>gender</th>\n      <th>education</th>\n      <th>marriage</th>\n      <th>age</th>\n      <th>behind1</th>\n      <th>behind2</th>\n      <th>behind3</th>\n      <th>behind4</th>\n      <th>behind5</th>\n      <th>...</th>\n      <th>billed3</th>\n      <th>billed4</th>\n      <th>billed5</th>\n      <th>billed6</th>\n      <th>paid1</th>\n      <th>paid2</th>\n      <th>paid3</th>\n      <th>paid4</th>\n      <th>paid5</th>\n      <th>paid6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1074.16</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>414.66</td>\n      <td>450.43</td>\n      <td>491.10</td>\n      <td>530.92</td>\n      <td>53.71</td>\n      <td>71.61</td>\n      <td>53.71</td>\n      <td>53.71</td>\n      <td>53.71</td>\n      <td>71.61</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5370.78</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4177.89</td>\n      <td>3637.13</td>\n      <td>2783.53</td>\n      <td>2766.45</td>\n      <td>160.62</td>\n      <td>151.64</td>\n      <td>113.18</td>\n      <td>94.78</td>\n      <td>95.56</td>\n      <td>95.56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2506.36</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2453.73</td>\n      <td>2497.52</td>\n      <td>2510.34</td>\n      <td>2513.96</td>\n      <td>87.04</td>\n      <td>111.43</td>\n      <td>107.42</td>\n      <td>87.29</td>\n      <td>89.51</td>\n      <td>91.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4654.68</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>49</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>579.04</td>\n      <td>605.04</td>\n      <td>402.31</td>\n      <td>248.63</td>\n      <td>57.65</td>\n      <td>64.74</td>\n      <td>251.14</td>\n      <td>0.97</td>\n      <td>251.03</td>\n      <td>157.83</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1790.26</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1516.74</td>\n      <td>700.85</td>\n      <td>726.67</td>\n      <td>696.02</td>\n      <td>71.61</td>\n      <td>53.71</td>\n      <td>35.81</td>\n      <td>64.45</td>\n      <td>0.00</td>\n      <td>35.81</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "source": [
    "# Standardize Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_ss = scaler.transform(X_train)\n",
    "X_valid_ss = scaler.transform(X_valid)"
   ]
  },
  {
   "source": [
    "# Importing Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.821\nF1 Score:  0.4688427299703264\nROC-AUC Score:  0.7808000154695354\nRecall Score:  0.361005331302361\nPrecision Score:  0.6685472496473907\nPR-AUC Score:  0.5454979238062434\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42).fit(X_train_ss, y_train)\n",
    "y_pred = gbc.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  35 out of  35 | elapsed:   27.1s finished\n",
      "Best: 0.780421 using {'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': range(20, 81, 10)}\n",
    "gs_gbc = GridSearchCV(estimator = GradientBoostingClassifier(random_state=42),\n",
    "                      param_grid = params, \n",
    "                      n_jobs = 4,\n",
    "                      iid = False, \n",
    "                      cv = 5, \n",
    "                      scoring = 'roc_auc',\n",
    "                      verbose = 1).fit(X_train_ss, y_train)\n",
    "print(\"Best: %f using %s\" % (gs_gbc.best_score_, gs_gbc.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8213333333333334\nF1 Score:  0.46719681908548716\nROC-AUC Score:  0.7803374731131514\nRecall Score:  0.357958872810358\nPrecision Score:  0.6723891273247496\nPR-AUC Score:  0.5442969677371212\n"
     ]
    }
   ],
   "source": [
    "y_pred_gsgbc = gs_gbc.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gsgbc, gs_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:  9.0min finished\n",
      "Best: 0.781568 using {'max_depth': 5, 'min_samples_split': 1000}\n"
     ]
    }
   ],
   "source": [
    "params_2 = {'max_depth': range(5, 16, 2), 'min_samples_split': range(200, 1001, 200)}\n",
    "gs_gbc_2 = GridSearchCV(estimator = GradientBoostingClassifier(random_state=42, n_estimators=70),\n",
    "                        param_grid = params_2, \n",
    "                        n_jobs = 4,\n",
    "                        iid = False, \n",
    "                        cv = 5, \n",
    "                        scoring = 'roc_auc',\n",
    "                        verbose = 1).fit(X_train_ss, y_train)\n",
    "print(\"Best: %f using %s\" % (gs_gbc_2.best_score_, gs_gbc_2.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8201666666666667\nF1 Score:  0.46504709965294994\nROC-AUC Score:  0.7815831606958106\nRecall Score:  0.3571972581873572\nPrecision Score:  0.6661931818181818\nPR-AUC Score:  0.5468047052839891\n"
     ]
    }
   ],
   "source": [
    "y_pred_gsgbc_2 = gs_gbc_2.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gsgbc_2, gs_gbc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 210 out of 210 | elapsed:  8.0min finished\n",
      "Best: 0.783317 using {'min_samples_leaf': 30, 'min_samples_split': 1800}\n"
     ]
    }
   ],
   "source": [
    "params_3 = {'min_samples_split': range(1000, 2001, 200), 'min_samples_leaf': range(10, 71, 10)}\n",
    "gs_gbc_3 = GridSearchCV(estimator = GradientBoostingClassifier(random_state=42, n_estimators=70, max_depth=5),\n",
    "                        param_grid = params_3, \n",
    "                        n_jobs = 4,\n",
    "                        iid = False, \n",
    "                        cv = 5, \n",
    "                        scoring = 'roc_auc',\n",
    "                        verbose = 1).fit(X_train_ss, y_train)\n",
    "print(\"Best: %f using %s\" % (gs_gbc_3.best_score_, gs_gbc_3.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8205\nF1 Score:  0.46603867129400095\nROC-AUC Score:  0.7830263610956786\nRecall Score:  0.357958872810358\nPrecision Score:  0.6676136363636364\nPR-AUC Score:  0.5485997794238602\n"
     ]
    }
   ],
   "source": [
    "y_pred_gsgbc_3 = gs_gbc_3.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gsgbc_3, gs_gbc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  35 out of  35 | elapsed:   24.4s finished\n",
      "Best: 0.781619 using {'max_features': 9}\n"
     ]
    }
   ],
   "source": [
    "params_4 = {'max_features': range(7, 20, 2)}\n",
    "gs_gbc_4 = GridSearchCV(estimator = GradientBoostingClassifier(random_state=42, n_estimators=70, min_samples_split=1800, min_samples_leaf=30),\n",
    "                        param_grid = params_4, \n",
    "                        n_jobs = 4,\n",
    "                        iid = False, \n",
    "                        cv = 5, \n",
    "                        scoring = 'roc_auc',\n",
    "                        verbose = 1).fit(X_train_ss, y_train)\n",
    "print(\"Best: %f using %s\" % (gs_gbc_4.best_score_, gs_gbc_4.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8201666666666667\nF1 Score:  0.46504709965294994\nROC-AUC Score:  0.7804782751338107\nRecall Score:  0.3571972581873572\nPrecision Score:  0.6661931818181818\nPR-AUC Score:  0.5437970926408667\n"
     ]
    }
   ],
   "source": [
    "y_pred_gsgbc_4 = gs_gbc_4.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gsgbc_4, gs_gbc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  35 out of  35 | elapsed:   13.5s finished\n",
      "Best: 0.781776 using {'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "params_5 = {'subsample': [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]}\n",
    "gs_gbc_5 = GridSearchCV(estimator = GradientBoostingClassifier(random_state=42, n_estimators=70, min_samples_split=1800, \n",
    "                                                               min_samples_leaf=30, max_features=9),\n",
    "                        param_grid = params_5, \n",
    "                        n_jobs = 4,\n",
    "                        iid = False, \n",
    "                        cv = 5, \n",
    "                        scoring = 'roc_auc',\n",
    "                        verbose = 1).fit(X_train_ss, y_train)\n",
    "print(\"Best: %f using %s\" % (gs_gbc_5.best_score_, gs_gbc_5.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8195\nF1 Score:  0.4672897196261682\nROC-AUC Score:  0.7789054036289385\nRecall Score:  0.3617669459253618\nPrecision Score:  0.6597222222222222\nPR-AUC Score:  0.5372269413921732\n"
     ]
    }
   ],
   "source": [
    "y_pred_gsgbc_5 = gs_gbc_5.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gsgbc_5, gs_gbc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8191666666666667\nF1 Score:  0.4678764100049043\nROC-AUC Score:  0.7805194676464905\nRecall Score:  0.3632901751713633\nPrecision Score:  0.6570247933884298\nPR-AUC Score:  0.5413461845711439\n"
     ]
    }
   ],
   "source": [
    "gbc_tuned = GradientBoostingClassifier(random_state=42, n_estimators=140, min_samples_split=1800, \n",
    "                                       min_samples_leaf=30, max_features=9, subsample=0.7, learning_rate=0.05).fit(X_train_ss, y_train)\n",
    "y_pred_gbc_tuned = gbc_tuned.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gbc_tuned, gbc_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.82\nF1 Score:  0.46745562130177515\nROC-AUC Score:  0.7811059937787119\nRecall Score:  0.361005331302361\nPrecision Score:  0.6629370629370629\nPR-AUC Score:  0.5410529462314562\n"
     ]
    }
   ],
   "source": [
    "gbc_tuned_2 = GradientBoostingClassifier(random_state=42, n_estimators=800, min_samples_split=1800, \n",
    "                                       min_samples_leaf=30, max_features=9, subsample=0.7, learning_rate=0.01).fit(X_train_ss, y_train)\n",
    "y_pred_gbc_tuned_2 = gbc_tuned_2.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gbc_tuned_2, gbc_tuned_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8201666666666667\nF1 Score:  0.46925725528775203\nROC-AUC Score:  0.781126386916153\nRecall Score:  0.3632901751713633\nPrecision Score:  0.6625\nPR-AUC Score:  0.5417112302681786\n"
     ]
    }
   ],
   "source": [
    "gbc_tuned_3 = GradientBoostingClassifier(random_state=42, n_estimators=1600, min_samples_split=1800, \n",
    "                                       min_samples_leaf=30, max_features=9, subsample=0.7, learning_rate=0.005).fit(X_train_ss, y_train)\n",
    "y_pred_gbc_tuned_3 = gbc_tuned_3.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gbc_tuned_3, gbc_tuned_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_tuned_4 = GradientBoostingClassifier(random_state=42, n_estimators=1600, min_samples_split=1800, \n",
    "                                       min_samples_leaf=30, max_features=9, subsample=0.7, learning_rate=0.005).fit(X_train_ss, y_train)\n",
    "y_pred_gbc_tuned_4 = gbc_tuned_4.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_gbc_tuned_4, gbc_tuned_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"data/best_model.pickle\",\"rb\")\n",
    "rfcb = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, n_estimators=400)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "rfcb"
   ]
  },
  {
   "source": [
    "# Dummy Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.7811666666666667\nF1 Score:  0.0\nROC-AUC Score:  0.5\nRecall Score:  0.0\nPrecision Score:  0.0\nPR-AUC Score:  0.21883333333333332\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='most_frequent').fit(X_train_ss, y_train)\n",
    "y_pred_dc = dc.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_dc, dc)"
   ]
  },
  {
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "- Bagging and boosting algorithms\n",
    "- Easy Ensemble Classifier: bag of balanced boosted learners known as EasyEnsemble\n",
    "- classifier is ensemble of Adaboost learners trained on different balanced bootstrap samples\n",
    "- balancing achieved by random under-sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bagging Classifier\n",
    "\n",
    "Instead of using a single tree, we will check if an ensemble of decsion tree can actually alleviate the issue induced by the class imbalancing. First, we will use a bagging classifier and its counter part which internally uses a random under-sampling to balanced each boostrap sample.\n",
    "\n",
    "Balancing each bootstrap sample allows to increase significantly the balanced accuracy and the geometric mean."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.8118333333333333\nF1 Score:  0.457993278924628\nROC-AUC Score:  0.7488929613776726\nRecall Score:  0.3632901751713633\nPrecision Score:  0.6194805194805195\nPR-AUC Score:  0.5017609097848447\n\nBalanced Accuracy:  0.650388420207828\nGeometric Mean:  0.583592062006858\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(n_estimators=50, random_state=42).fit(X_train_ss, y_train)\n",
    "y_pred_bc = bc.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_bc, bc)\n",
    "print(\"\")\n",
    "print('Balanced Accuracy: ', balanced_accuracy_score(y_valid, y_pred_bc))\n",
    "print('Geometric Mean: ', geometric_mean_score(y_valid, y_pred_bc))"
   ]
  },
  {
   "source": [
    "## Balanced Bagging Classifier\n",
    "\n",
    "A Bagging classifier with additional balancing.\n",
    "\n",
    "This implementation of Bagging is similar to the scikit-learn implementation. It includes an additional step to balance the training set at fit time using a given sampler.\n",
    "\n",
    "This classifier can serves as a basis to implement various methods such as Exactly Balanced Bagging, Roughly Balanced Bagging, Over-Bagging, or SMOTE-Bagging."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.783\nF1 Score:  0.5244704163623083\nROC-AUC Score:  0.7652801066487965\nRecall Score:  0.5468392993145469\nPrecision Score:  0.503859649122807\nPR-AUC Score:  0.5141101768863308\n\nValidation Balanced Accuracy:  0.6979982713769235\nValidation Geometric Mean:  0.681434187585433\n"
     ]
    }
   ],
   "source": [
    "bbc = BalancedBaggingClassifier(n_estimators=50, random_state=42).fit(X_train_ss, y_train)\n",
    "y_pred_bbc = bbc.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_bbc, bbc)\n",
    "print(\"\")\n",
    "print('Validation Balanced Accuracy: ', balanced_accuracy_score(y_valid, y_pred_bbc))\n",
    "print('Validation Geometric Mean: ', geometric_mean_score(y_valid, y_pred_bbc))"
   ]
  },
  {
   "source": [
    "## Balanced Bagging Classifier with Gradient Boosting Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.7618333333333334\nF1 Score:  0.5331590983338778\nROC-AUC Score:  0.7816608333627179\nRecall Score:  0.6214775323686215\nPrecision Score:  0.4668192219679634\nPR-AUC Score:  0.541759943308943\n"
     ]
    }
   ],
   "source": [
    "bbc3 = BalancedBaggingClassifier(\n",
    "        base_estimator=HistGradientBoostingClassifier(random_state=42),\n",
    "        n_estimators=10,\n",
    "        random_state=42,\n",
    "        n_jobs=2).fit(X_train_ss, y_train)\n",
    "y_pred_bbc3 = bbc3.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_bbc3, bbc3)"
   ]
  },
  {
   "source": [
    "## Balanced Random Forest Classifier\n",
    "\n",
    "Random forest is another popular ensemble method and it is usually outperforming bagging. Here, we used a vanilla random forest and its balanced counterpart in which each bootstrap sample is balanced.\n",
    "\n",
    "Similarly to the previous experiment, the balanced classifier outperform the classifier which learn from imbalanced bootstrap samples. In addition, random forest outsperforms the bagging classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.7426666666666667\nF1 Score:  0.5199004975124378\nROC-AUC Score:  0.7718711524202592\nRecall Score:  0.6367098248286367\nPrecision Score:  0.4393063583815029\nPR-AUC Score:  0.5237137210202338\n"
     ]
    }
   ],
   "source": [
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42).fit(X_train_ss, y_train)\n",
    "y_pred_brf = brf.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_brf, brf)"
   ]
  },
  {
   "source": [
    "## RUSBoostClassifier\n",
    "\n",
    "Random under-sampling integrated in the learning of AdaBoost.\n",
    "\n",
    "During learning, the problem of class balancing is alleviated by random under-sampling the sample at each iteration of the boosting algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.7511666666666666\nF1 Score:  0.5200900032144005\nROC-AUC Score:  0.7648475446418779\nRecall Score:  0.6161462300076161\nPrecision Score:  0.449944382647386\nPR-AUC Score:  0.5211050914562826\n"
     ]
    }
   ],
   "source": [
    "rbc = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R', random_state=42).fit(X_train_ss, y_train)\n",
    "y_pred_rbc = rbc.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_rbc, rbc)"
   ]
  },
  {
   "source": [
    "## Easy Ensemble Classifier\n",
    "\n",
    "Bag of balanced boosted learners also known as EasyEnsemble.\n",
    "\n",
    "This algorithm is known as EasyEnsemble. The classifier is an ensemble of AdaBoost learners trained on different balanced boostrap samples. The balancing is achieved by random under-sampling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score:  0.759\nF1 Score:  0.5271419228253761\nROC-AUC Score:  0.7765765235826728\nRecall Score:  0.6138613861386139\nPrecision Score:  0.46189111747851\nPR-AUC Score:  0.5280535859382768\n"
     ]
    }
   ],
   "source": [
    "eec = EasyEnsembleClassifier(random_state=42).fit(X_train_ss, y_train) \n",
    "y_pred_eec = eec.predict(X_valid_ss)\n",
    "get_metric(X_valid_ss, y_valid, y_pred_eec, eec)"
   ]
  },
  {
   "source": [
    "# Undersampling Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## TomekLinks\n",
    "\n",
    "- Detects Tomek's links, which exists if two samples from different categories are nearest neighbors\n",
    "- using `sampling_strategy` controls which of the sample will be removed, majority or minority, where `auto` is removing majority class\n",
    "- setting to `all` removes both samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 15100, 1: 4656})\n",
      "Accuracy Score:  0.819\n",
      "F1 Score:  0.4843304843304843\n",
      "ROC-AUC Score:  0.7827677501137059\n",
      "Recall Score:  0.38842345773038844\n",
      "Precision Score:  0.6431273644388399\n",
      "PR-AUC Score:  0.5453507704238421\n"
     ]
    }
   ],
   "source": [
    "tl = TomekLinks()\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, tl, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tl, y_train_tl = tl.fit_sample(X_train_ss, y_train)\n",
    "tlm = gbc.fit(X_train_tl, y_train_tl)\n",
    "y_pred_tl = tlm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## Edited Nearest Neighbours\n",
    "\n",
    "- applies nearest-neighbors algorithm and removes samples which do not agree enough with neighborhood or not in the same class as the neighbors\n",
    "- two selection criteria:  `mode` and `all`, majority vs. all, so that more samples will be excluded with `all`\n",
    "- `RepeatedEditedNearestNeighbours()` repeat algorithm muliple times resulting in more samples removed\n",
    "- `AllKNN()` repeats algorithm but increase the number of nearest neighbors at each iteration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 9974, 1: 4656})\n",
      "Accuracy Score:  0.791\n",
      "F1 Score:  0.5399853264856933\n",
      "ROC-AUC Score:  0.7810130465706137\n",
      "Recall Score:  0.5605483625285606\n",
      "Precision Score:  0.5208775654635527\n",
      "PR-AUC Score:  0.537673190195926\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, enn, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enn, y_train_enn = enn.fit_sample(X_train_ss, y_train)\n",
    "ennm = rfcb.fit(X_train_enn, y_train_enn)\n",
    "y_pred_enn = ennm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## Near Miss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 4656, 1: 4656})\n",
      "Accuracy Score:  0.49316666666666664\n",
      "F1 Score:  0.39386087303169226\n",
      "ROC-AUC Score:  0.6087256466533887\n",
      "Recall Score:  0.7524752475247525\n",
      "Precision Score:  0.26673866090712745\n",
      "PR-AUC Score:  0.26422653123571577\n"
     ]
    }
   ],
   "source": [
    "ns = NearMiss(version=1, n_neighbors=3)\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, ns, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ns, y_train_ns = ns.fit_sample(X_train_ss, y_train)\n",
    "nsm = gbc.fit(X_train_ns, y_train_ns)\n",
    "y_pred_ns = nsm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## Neighborhood Cleaning Rule"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 10218, 1: 4656})\n",
      "Accuracy Score:  0.7936666666666666\n",
      "F1 Score:  0.5411415863602669\n",
      "ROC-AUC Score:  0.7785372709367242\n",
      "Recall Score:  0.555978674790556\n",
      "Precision Score:  0.5270758122743683\n",
      "PR-AUC Score:  0.5375883115780334\n"
     ]
    }
   ],
   "source": [
    "ncr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, ncr, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ncr, y_train_ncr = ncr.fit_sample(X_train_ss, y_train)\n",
    "ncrm = gbc.fit(X_train_ncr, y_train_ncr)\n",
    "y_pred_ncr = ncrm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## One Sided Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 13843, 1: 4656})\n",
      "Accuracy Score:  0.8191666666666667\n",
      "F1 Score:  0.485538169748696\n",
      "ROC-AUC Score:  0.7795020857061006\n",
      "Recall Score:  0.38994668697638996\n",
      "Precision Score:  0.6432160804020101\n",
      "PR-AUC Score:  0.5436972301524162\n"
     ]
    }
   ],
   "source": [
    "oss = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, oss, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oss, y_train_oss = oss.fit_sample(X_train_ss, y_train)\n",
    "ossm = gbc.fit(X_train_oss, y_train_oss)\n",
    "y_pred_oss = ossm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "# Other Undersampling Methods\n",
    "\n",
    "- Methods that select samples to keep\n",
    "    - Condensed Nearest Neighbors\n",
    "    - Near Miss\n",
    "- Methods that select samples to delete\n",
    "- Methods that use combination of both techniques\n",
    "    - Neighborhood Cleaning Rule\n",
    "    - One Sided Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Oversampling Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## SMOTE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 16344, 1: 16344})\n",
      "Accuracy Score:  0.7935\n",
      "F1 Score:  0.516582130316036\n",
      "ROC-AUC Score:  0.7640743928654243\n",
      "Recall Score:  0.5041888804265042\n",
      "Precision Score:  0.5296\n",
      "PR-AUC Score:  0.5268566190077079\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, sm, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = sm.fit_sample(X_train_ss, y_train)\n",
    "smm = gbc.fit(X_train_sm, y_train_sm)\n",
    "y_pred_sm = smm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## SVMSMOTE\n",
    "\n",
    "- Variant of SMOTE algorithm which uses an SVM algorithm to detect sample for generating new synthetic samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 16344, 1: 16344})\n",
      "Accuracy Score:  0.7995\n",
      "F1 Score:  0.5287896592244419\n",
      "ROC-AUC Score:  0.771839790862282\n",
      "Recall Score:  0.5140898705255141\n",
      "Precision Score:  0.5443548387096774\n",
      "PR-AUC Score:  0.5200407308276643\n"
     ]
    }
   ],
   "source": [
    "svmsm = SVMSMOTE()\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, svmsm, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm, y_train_svm = svmsm.fit_sample(X_train_ss, y_train)\n",
    "svmsmote = gbc.fit(X_train_svm, y_train_svm)\n",
    "y_pred_svmsm = svmsmote.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## ADASYN\n",
    "\n",
    "- Oversample using Adaptive Synthetic (ADASYN) algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 16344, 1: 15923})\n",
      "Accuracy Score:  0.7905\n",
      "F1 Score:  0.5099415204678363\n",
      "ROC-AUC Score:  0.7601081307520225\n",
      "Recall Score:  0.49809596344249807\n",
      "Precision Score:  0.5223642172523961\n",
      "PR-AUC Score:  0.522026068617647\n"
     ]
    }
   ],
   "source": [
    "adsn = ADASYN()\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, adsn, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adsn, y_train_adsn = adsn.fit_sample(X_train_ss, y_train)\n",
    "adsnm = gbc.fit(X_train_adsn, y_train_adsn)\n",
    "y_pred_adsnm = adsnm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "# Combined Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## SMOTE-Tomek\n",
    "\n",
    "- oversampling using SMOTE and cleaning using Tomek Links"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({0: 15938, 1: 15938})\n",
      "Accuracy Score:  0.7951666666666667\n",
      "F1 Score:  0.5212310089598754\n",
      "ROC-AUC Score:  0.76603782138894\n",
      "Recall Score:  0.5095201827875095\n",
      "Precision Score:  0.5334928229665071\n",
      "PR-AUC Score:  0.5255432844118494\n"
     ]
    }
   ],
   "source": [
    "smtk = SMOTETomek()\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, smtk, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smt, y_train_smt = smtk.fit_sample(X_train_ss, y_train)\n",
    "smtkm = gbc.fit(X_train_smt, y_train_smt)\n",
    "y_pred_smtk = smtkm.predict(X_valid_ss)"
   ]
  },
  {
   "source": [
    "## SMOTE-ENN\n",
    "\n",
    "- Oversampling using SMOTE and cleaning using ENN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Count:  Counter({1: 12432, 0: 8515})\n",
      "Accuracy Score:  0.73\n",
      "F1 Score:  0.5117540687160941\n",
      "ROC-AUC Score:  0.7706350520496241\n",
      "Recall Score:  0.6466108149276466\n",
      "Precision Score:  0.4234413965087282\n",
      "PR-AUC Score:  0.52638475073663\n"
     ]
    }
   ],
   "source": [
    "smenn = SMOTEENN(sampling_strategy=\"minority\", n_jobs= -1)\n",
    "sampling(X_train_ss, y_train, X_valid_ss, y_valid, smenn, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sme, y_train_sme = smenn.fit_sample(X_train, y_train)\n",
    "smennm = gbc.fit(X_train_sme, y_train_sme)\n",
    "y_pred_smenn = smennm.predict(X_valid_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy': [accuracy(y_valid, y_pred_bc),\n",
    "                     accuracy(y_valid, y_pred_bbc),\n",
    "                     accuracy(y_valid, y_pred_bbc3),\n",
    "                     accuracy(y_valid, y_pred_brf),\n",
    "                     accuracy(y_valid, y_pred_rbc),\n",
    "                     accuracy(y_valid, y_pred_eec),\n",
    "                     accuracy(y_valid, y_pred_tl),\n",
    "                     accuracy(y_valid, y_pred_enn),\n",
    "                     accuracy(y_valid, y_pred_sm),\n",
    "                     accuracy(y_valid, y_pred_svmsm),\n",
    "                     accuracy(y_valid, y_pred_adsnm),\n",
    "                     accuracy(y_valid, y_pred_smtk),\n",
    "                     accuracy(y_valid, y_pred_smenn)],\n",
    "    'F1 Score': [f1_score(y_valid, y_pred_bc),\n",
    "                 f1_score(y_valid, y_pred_bbc),\n",
    "                 f1_score(y_valid, y_pred_bbc3),\n",
    "                 f1_score(y_valid, y_pred_brf),\n",
    "                 f1_score(y_valid, y_pred_rbc),\n",
    "                 f1_score(y_valid, y_pred_eec),\n",
    "                 f1_score(y_valid, y_pred_tl),\n",
    "                 f1_score(y_valid, y_pred_enn),\n",
    "                 f1_score(y_valid, y_pred_sm),\n",
    "                 f1_score(y_valid, y_pred_svmsm),\n",
    "                 f1_score(y_valid, y_pred_adsnm),\n",
    "                 f1_score(y_valid, y_pred_smtk),\n",
    "                 f1_score(y_valid, y_pred_smenn)],\n",
    "    'ROC-AUC Score': [auc(X_valid_ss, y_valid, bc),\n",
    "                      auc(X_valid_ss, y_valid, bbc),\n",
    "                      auc(X_valid_ss, y_valid, bbc3),\n",
    "                      auc(X_valid_ss, y_valid, brf),\n",
    "                      auc(X_valid_ss, y_valid, rbc),\n",
    "                      auc(X_valid_ss, y_valid, eec),\n",
    "                      auc(X_valid_ss, y_valid, tlm),\n",
    "                      auc(X_valid_ss, y_valid, ennm),\n",
    "                      auc(X_valid_ss, y_valid, smm),\n",
    "                      auc(X_valid_ss, y_valid, svmsmote),\n",
    "                      auc(X_valid_ss, y_valid, adsnm),\n",
    "                      auc(X_valid_ss, y_valid, smtkm),\n",
    "                      auc(X_valid_ss, y_valid, smennm)],\n",
    "    'PR-AUC Score': [aps(X_valid_ss, y_valid, bc),\n",
    "                     aps(X_valid_ss, y_valid, bbc),\n",
    "                     aps(X_valid_ss, y_valid, bbc3),\n",
    "                     aps(X_valid_ss, y_valid, brf),\n",
    "                     aps(X_valid_ss, y_valid, rbc),\n",
    "                     aps(X_valid_ss, y_valid, eec),\n",
    "                     aps(X_valid_ss, y_valid, tlm),\n",
    "                     aps(X_valid_ss, y_valid, ennm),\n",
    "                     aps(X_valid_ss, y_valid, smm),\n",
    "                     aps(X_valid_ss, y_valid, svmsmote),\n",
    "                     aps(X_valid_ss, y_valid, adsnm),\n",
    "                     aps(X_valid_ss, y_valid, smtkm),\n",
    "                     aps(X_valid_ss, y_valid, smennm)]}\n",
    "scores = pd.DataFrame(data=data, index = ['Bagging Classifier',\n",
    "                                          'Balanced Bagging Classifier',\n",
    "                                          'BBC with Gradient Boosting',\n",
    "                                          'Balanced Random Forest',\n",
    "                                          'RUBoost Classifier',\n",
    "                                          'Easy Ensemble Classifier',\n",
    "                                          'Tomek Links',\n",
    "                                          'Edited Nearest Neighbours',\n",
    "                                          'SMOTE',\n",
    "                                          'SVM-SMOTE',\n",
    "                                          'ADASYN',\n",
    "                                          'SMOTE-Tomek',\n",
    "                                          'SMOTE-ENN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             Accuracy  F1 Score  ROC-AUC Score  PR-AUC Score\n",
       "Bagging Classifier           0.811833  0.457993       0.748893      0.501761\n",
       "Balanced Bagging Classifier  0.783000  0.524470       0.765280      0.514110\n",
       "BBC with Gradient Boosting   0.761833  0.533159       0.781661      0.541760\n",
       "Balanced Random Forest       0.742667  0.519900       0.771871      0.523714\n",
       "RUBoost Classifier           0.751167  0.520090       0.764848      0.521105\n",
       "Easy Ensemble Classifier     0.759000  0.527142       0.776577      0.528054\n",
       "Tomek Links                  0.819000  0.484330       0.764074      0.526857\n",
       "Edited Nearest Neighbours    0.795833  0.539300       0.443035      0.218539\n",
       "SMOTE                        0.793500  0.516582       0.764074      0.526857\n",
       "SVM-SMOTE                    0.798667  0.531783       0.764074      0.526857\n",
       "ADASYN                       0.786833  0.504839       0.764074      0.526857\n",
       "SMOTE-Tomek                  0.793833  0.518115       0.764074      0.526857\n",
       "SMOTE-ENN                    0.220833  0.359501       0.764074      0.526857"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n      <th>ROC-AUC Score</th>\n      <th>PR-AUC Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Bagging Classifier</th>\n      <td>0.811833</td>\n      <td>0.457993</td>\n      <td>0.748893</td>\n      <td>0.501761</td>\n    </tr>\n    <tr>\n      <th>Balanced Bagging Classifier</th>\n      <td>0.783000</td>\n      <td>0.524470</td>\n      <td>0.765280</td>\n      <td>0.514110</td>\n    </tr>\n    <tr>\n      <th>BBC with Gradient Boosting</th>\n      <td>0.761833</td>\n      <td>0.533159</td>\n      <td>0.781661</td>\n      <td>0.541760</td>\n    </tr>\n    <tr>\n      <th>Balanced Random Forest</th>\n      <td>0.742667</td>\n      <td>0.519900</td>\n      <td>0.771871</td>\n      <td>0.523714</td>\n    </tr>\n    <tr>\n      <th>RUBoost Classifier</th>\n      <td>0.751167</td>\n      <td>0.520090</td>\n      <td>0.764848</td>\n      <td>0.521105</td>\n    </tr>\n    <tr>\n      <th>Easy Ensemble Classifier</th>\n      <td>0.759000</td>\n      <td>0.527142</td>\n      <td>0.776577</td>\n      <td>0.528054</td>\n    </tr>\n    <tr>\n      <th>Tomek Links</th>\n      <td>0.819000</td>\n      <td>0.484330</td>\n      <td>0.764074</td>\n      <td>0.526857</td>\n    </tr>\n    <tr>\n      <th>Edited Nearest Neighbours</th>\n      <td>0.795833</td>\n      <td>0.539300</td>\n      <td>0.443035</td>\n      <td>0.218539</td>\n    </tr>\n    <tr>\n      <th>SMOTE</th>\n      <td>0.793500</td>\n      <td>0.516582</td>\n      <td>0.764074</td>\n      <td>0.526857</td>\n    </tr>\n    <tr>\n      <th>SVM-SMOTE</th>\n      <td>0.798667</td>\n      <td>0.531783</td>\n      <td>0.764074</td>\n      <td>0.526857</td>\n    </tr>\n    <tr>\n      <th>ADASYN</th>\n      <td>0.786833</td>\n      <td>0.504839</td>\n      <td>0.764074</td>\n      <td>0.526857</td>\n    </tr>\n    <tr>\n      <th>SMOTE-Tomek</th>\n      <td>0.793833</td>\n      <td>0.518115</td>\n      <td>0.764074</td>\n      <td>0.526857</td>\n    </tr>\n    <tr>\n      <th>SMOTE-ENN</th>\n      <td>0.220833</td>\n      <td>0.359501</td>\n      <td>0.764074</td>\n      <td>0.526857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}