{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('learn-env': conda)"
  },
  "interpreter": {
   "hash": "80773cdecc613a186b9eac051636553d2ff0f99c57590601666ed713bd5d0256"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Importing Packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for data cleaning and processing  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import modules for preprocessing\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "# pd.set_option('display.max_rows', 200)\n",
    "# pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bias_variance(model, X_train, y_train, X_test, y_test, loss_type):\n",
    "    avg_expected_loss, avg_bias, avg_variance = bias_variance_decomp(model, X_train.values, y_train.values, X_test.values, y_test.values, loss=loss_type, random_seed=42)\n",
    "    print('Average expected loss: %.3e' % avg_expected_loss)\n",
    "    print('Average bias: %.3e' % avg_bias)\n",
    "    print('Average variance: %.3e' % avg_variance)\n",
    "    return\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def train_test_metrics(y_train, y_test, y_train_pred, y_test_pred):\n",
    "\tprint('Training R^2 Score: ', round(r2_score(y_train, y_train_pred), 4))\n",
    "\tprint('Training RMSE: %d' % rmse(y_train, y_train_pred))\n",
    "\tprint('Testing R^2 Score: ', round(r2_score(y_test, y_test_pred), 4))\n",
    "\tprint('Testing RMSE: %d' % rmse(y_test, y_test_pred))\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n      <th>...</th>\n      <th>grade</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>yr_built</th>\n      <th>yr_renovated</th>\n      <th>zipcode</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7129300520</td>\n      <td>20141013T000000</td>\n      <td>221900.0</td>\n      <td>3</td>\n      <td>1.00</td>\n      <td>1180</td>\n      <td>5650</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7</td>\n      <td>1180</td>\n      <td>0</td>\n      <td>1955</td>\n      <td>0</td>\n      <td>98178</td>\n      <td>47.5112</td>\n      <td>-122.257</td>\n      <td>1340</td>\n      <td>5650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6414100192</td>\n      <td>20141209T000000</td>\n      <td>538000.0</td>\n      <td>3</td>\n      <td>2.25</td>\n      <td>2570</td>\n      <td>7242</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7</td>\n      <td>2170</td>\n      <td>400</td>\n      <td>1951</td>\n      <td>1991</td>\n      <td>98125</td>\n      <td>47.7210</td>\n      <td>-122.319</td>\n      <td>1690</td>\n      <td>7639</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5631500400</td>\n      <td>20150225T000000</td>\n      <td>180000.0</td>\n      <td>2</td>\n      <td>1.00</td>\n      <td>770</td>\n      <td>10000</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>770</td>\n      <td>0</td>\n      <td>1933</td>\n      <td>0</td>\n      <td>98028</td>\n      <td>47.7379</td>\n      <td>-122.233</td>\n      <td>2720</td>\n      <td>8062</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2487200875</td>\n      <td>20141209T000000</td>\n      <td>604000.0</td>\n      <td>4</td>\n      <td>3.00</td>\n      <td>1960</td>\n      <td>5000</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7</td>\n      <td>1050</td>\n      <td>910</td>\n      <td>1965</td>\n      <td>0</td>\n      <td>98136</td>\n      <td>47.5208</td>\n      <td>-122.393</td>\n      <td>1360</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1954400510</td>\n      <td>20150218T000000</td>\n      <td>510000.0</td>\n      <td>3</td>\n      <td>2.00</td>\n      <td>1680</td>\n      <td>8080</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>8</td>\n      <td>1680</td>\n      <td>0</td>\n      <td>1987</td>\n      <td>0</td>\n      <td>98074</td>\n      <td>47.6168</td>\n      <td>-122.045</td>\n      <td>1800</td>\n      <td>7503</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.400881e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.671272e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n      <th>condition</th>\n      <th>grade</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>yr_built</th>\n      <th>yr_renovated</th>\n      <th>zipcode</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.161300e+04</td>\n      <td>2.161300e+04</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>2.161300e+04</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n      <td>21613.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.580302e+09</td>\n      <td>5.400881e+05</td>\n      <td>3.370842</td>\n      <td>2.114757</td>\n      <td>2079.899736</td>\n      <td>1.510697e+04</td>\n      <td>1.494309</td>\n      <td>0.007542</td>\n      <td>0.234303</td>\n      <td>3.409430</td>\n      <td>7.656873</td>\n      <td>1788.390691</td>\n      <td>291.509045</td>\n      <td>1971.005136</td>\n      <td>84.402258</td>\n      <td>98077.939805</td>\n      <td>47.560053</td>\n      <td>-122.213896</td>\n      <td>1986.552492</td>\n      <td>12768.455652</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.876566e+09</td>\n      <td>3.671272e+05</td>\n      <td>0.930062</td>\n      <td>0.770163</td>\n      <td>918.440897</td>\n      <td>4.142051e+04</td>\n      <td>0.539989</td>\n      <td>0.086517</td>\n      <td>0.766318</td>\n      <td>0.650743</td>\n      <td>1.175459</td>\n      <td>828.090978</td>\n      <td>442.575043</td>\n      <td>29.373411</td>\n      <td>401.679240</td>\n      <td>53.505026</td>\n      <td>0.138564</td>\n      <td>0.140828</td>\n      <td>685.391304</td>\n      <td>27304.179631</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000102e+06</td>\n      <td>7.500000e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>290.000000</td>\n      <td>5.200000e+02</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>290.000000</td>\n      <td>0.000000</td>\n      <td>1900.000000</td>\n      <td>0.000000</td>\n      <td>98001.000000</td>\n      <td>47.155900</td>\n      <td>-122.519000</td>\n      <td>399.000000</td>\n      <td>651.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.123049e+09</td>\n      <td>3.219500e+05</td>\n      <td>3.000000</td>\n      <td>1.750000</td>\n      <td>1427.000000</td>\n      <td>5.040000e+03</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n      <td>1190.000000</td>\n      <td>0.000000</td>\n      <td>1951.000000</td>\n      <td>0.000000</td>\n      <td>98033.000000</td>\n      <td>47.471000</td>\n      <td>-122.328000</td>\n      <td>1490.000000</td>\n      <td>5100.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.904930e+09</td>\n      <td>4.500000e+05</td>\n      <td>3.000000</td>\n      <td>2.250000</td>\n      <td>1910.000000</td>\n      <td>7.618000e+03</td>\n      <td>1.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n      <td>1560.000000</td>\n      <td>0.000000</td>\n      <td>1975.000000</td>\n      <td>0.000000</td>\n      <td>98065.000000</td>\n      <td>47.571800</td>\n      <td>-122.230000</td>\n      <td>1840.000000</td>\n      <td>7620.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.308900e+09</td>\n      <td>6.450000e+05</td>\n      <td>4.000000</td>\n      <td>2.500000</td>\n      <td>2550.000000</td>\n      <td>1.068800e+04</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>8.000000</td>\n      <td>2210.000000</td>\n      <td>560.000000</td>\n      <td>1997.000000</td>\n      <td>0.000000</td>\n      <td>98118.000000</td>\n      <td>47.678000</td>\n      <td>-122.125000</td>\n      <td>2360.000000</td>\n      <td>10083.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.900000e+09</td>\n      <td>7.700000e+06</td>\n      <td>33.000000</td>\n      <td>8.000000</td>\n      <td>13540.000000</td>\n      <td>1.651359e+06</td>\n      <td>3.500000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>5.000000</td>\n      <td>13.000000</td>\n      <td>9410.000000</td>\n      <td>4820.000000</td>\n      <td>2015.000000</td>\n      <td>2015.000000</td>\n      <td>98199.000000</td>\n      <td>47.777600</td>\n      <td>-121.315000</td>\n      <td>6210.000000</td>\n      <td>871200.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "source": [
    "# Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sale date for later processing\n",
    "df['sale_date'] = [x[:8] for x in df.date]\n",
    "df.sale_date = df.sale_date.apply(lambda x: datetime.strptime(x, '%Y%m%d'))\n",
    "df.drop(columns='date', inplace=True)\n",
    "df.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "# Replace anomalous bedroom value and check values in column\n",
    "df.replace({'bedrooms': {33: 3}}, inplace=True)\n",
    "df.replace({'bathrooms': {0: 0.25}}, inplace=True)\n",
    "\n",
    "# Create new feature to incorporate age at the time of sale\n",
    "df['sale_age'] = df.sale_date.dt.year - df[['yr_built', 'yr_renovated']].max(axis=1)\n",
    "df.replace({'sale_age': {-1: 0}}, inplace=True)\n",
    "\n",
    "# Create new feature for age from year built\n",
    "df['age'] = df.sale_date.dt.year - df.yr_built\n",
    "df.replace({'age': {-1: 0}}, inplace=True)\n",
    "\n",
    "# Create binary variables for whether there has been a renovation, the property has a bathroom, and has been viewed\n",
    "df['renovated'] = df.yr_renovated.apply(lambda x: x if x==0 else 1)\n",
    "df['basement'] = df.sqft_basement.apply(lambda x: x if x==0 else 1)\n",
    "df['viewed'] = df.view.apply(lambda x: x if x==0 else 1)\n",
    "\n",
    "# Drop original columms as well as the sale_date columns since it is in datetime format\n",
    "df.drop(['yr_built', 'yr_renovated', 'sale_date', 'sqft_basement', 'view'], inplace=True, axis=1)\n",
    "\n",
    "# Drop latitude and longitude as zip code has stronger correlation\n",
    "df.drop(['lat', 'long'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   condition  grade  sqft_above  zipcode  sqft_living15  sqft_lot15  sale_age  \\\n",
       "0          3      7        1180    98178           1340        5650        59   \n",
       "1          3      7        2170    98125           1690        7639        23   \n",
       "2          3      6         770    98028           2720        8062        82   \n",
       "3          5      7        1050    98136           1360        5000        49   \n",
       "4          3      8        1680    98074           1800        7503        28   \n",
       "\n",
       "   age  renovated  basement  viewed  \n",
       "0   59          0         0       0  \n",
       "1   63          1         1       0  \n",
       "2   82          0         0       0  \n",
       "3   49          0         1       0  \n",
       "4   28          0         0       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>condition</th>\n      <th>grade</th>\n      <th>sqft_above</th>\n      <th>zipcode</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n      <th>sale_age</th>\n      <th>age</th>\n      <th>renovated</th>\n      <th>basement</th>\n      <th>viewed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>221900.0</td>\n      <td>3</td>\n      <td>1.00</td>\n      <td>1180</td>\n      <td>5650</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1180</td>\n      <td>98178</td>\n      <td>1340</td>\n      <td>5650</td>\n      <td>59</td>\n      <td>59</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>538000.0</td>\n      <td>3</td>\n      <td>2.25</td>\n      <td>2570</td>\n      <td>7242</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2170</td>\n      <td>98125</td>\n      <td>1690</td>\n      <td>7639</td>\n      <td>23</td>\n      <td>63</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>180000.0</td>\n      <td>2</td>\n      <td>1.00</td>\n      <td>770</td>\n      <td>10000</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>770</td>\n      <td>98028</td>\n      <td>2720</td>\n      <td>8062</td>\n      <td>82</td>\n      <td>82</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>604000.0</td>\n      <td>4</td>\n      <td>3.00</td>\n      <td>1960</td>\n      <td>5000</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1050</td>\n      <td>98136</td>\n      <td>1360</td>\n      <td>5000</td>\n      <td>49</td>\n      <td>49</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000.0</td>\n      <td>3</td>\n      <td>2.00</td>\n      <td>1680</td>\n      <td>8080</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>8</td>\n      <td>1680</td>\n      <td>98074</td>\n      <td>1800</td>\n      <td>7503</td>\n      <td>28</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "# Dummy Variables and Polynomial/Interaction Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   bdr_1  bdr_2  bdr_3  bdr_4  bdr_5  bdr_6  bdr_7  bdr_8  bdr_9  bdr_10  ...  \\\n",
       "0      0      0      1      0      0      0      0      0      0       0  ...   \n",
       "1      0      0      1      0      0      0      0      0      0       0  ...   \n",
       "2      0      1      0      0      0      0      0      0      0       0  ...   \n",
       "3      0      0      0      1      0      0      0      0      0       0  ...   \n",
       "4      0      0      1      0      0      0      0      0      0       0  ...   \n",
       "\n",
       "   zip_98146  zip_98148  zip_98155  zip_98166  zip_98168  zip_98177  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   zip_98178  zip_98188  zip_98198  zip_98199  \n",
       "0          1          0          0          0  \n",
       "1          0          0          0          0  \n",
       "2          0          0          0          0  \n",
       "3          0          0          0          0  \n",
       "4          0          0          0          0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bdr_1</th>\n      <th>bdr_2</th>\n      <th>bdr_3</th>\n      <th>bdr_4</th>\n      <th>bdr_5</th>\n      <th>bdr_6</th>\n      <th>bdr_7</th>\n      <th>bdr_8</th>\n      <th>bdr_9</th>\n      <th>bdr_10</th>\n      <th>...</th>\n      <th>zip_98146</th>\n      <th>zip_98148</th>\n      <th>zip_98155</th>\n      <th>zip_98166</th>\n      <th>zip_98168</th>\n      <th>zip_98177</th>\n      <th>zip_98178</th>\n      <th>zip_98188</th>\n      <th>zip_98198</th>\n      <th>zip_98199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 129 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Grab indices of columns for creating dummy variables and create dataframe with dummy variables\n",
    "dum_feat = df[['bedrooms', 'bathrooms', 'floors', 'condition', 'grade', 'zipcode']]\n",
    "dum_index = dum_feat.columns\n",
    "\n",
    "# Create dummy variables then drop one of the dummy variables, as well as original categorical variable used in creating the dummy variables\n",
    "df_dum = pd.get_dummies(data=dum_feat, columns=dum_index, drop_first=True, prefix=['bdr', 'bth', 'flr', 'cnd', 'grd', 'zip'])\n",
    "df_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target variable\n",
    "y = df['price']"
   ]
  },
  {
   "source": [
    "# Baseline Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sqft_living  sqft_lot  waterfront  sqft_above  sqft_living15  sqft_lot15  \\\n",
       "0         1180      5650           0        1180           1340        5650   \n",
       "1         2570      7242           0        2170           1690        7639   \n",
       "2          770     10000           0         770           2720        8062   \n",
       "3         1960      5000           0        1050           1360        5000   \n",
       "4         1680      8080           0        1680           1800        7503   \n",
       "\n",
       "   sale_age  age  renovated  basement  ...  zip_98146  zip_98148  zip_98155  \\\n",
       "0        59   59          0         0  ...          0          0          0   \n",
       "1        23   63          1         1  ...          0          0          0   \n",
       "2        82   82          0         0  ...          0          0          0   \n",
       "3        49   49          0         1  ...          0          0          0   \n",
       "4        28   28          0         0  ...          0          0          0   \n",
       "\n",
       "   zip_98166  zip_98168  zip_98177  zip_98178  zip_98188  zip_98198  zip_98199  \n",
       "0          0          0          0          1          0          0          0  \n",
       "1          0          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>waterfront</th>\n      <th>sqft_above</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n      <th>sale_age</th>\n      <th>age</th>\n      <th>renovated</th>\n      <th>basement</th>\n      <th>...</th>\n      <th>zip_98146</th>\n      <th>zip_98148</th>\n      <th>zip_98155</th>\n      <th>zip_98166</th>\n      <th>zip_98168</th>\n      <th>zip_98177</th>\n      <th>zip_98178</th>\n      <th>zip_98188</th>\n      <th>zip_98198</th>\n      <th>zip_98199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1180</td>\n      <td>5650</td>\n      <td>0</td>\n      <td>1180</td>\n      <td>1340</td>\n      <td>5650</td>\n      <td>59</td>\n      <td>59</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2570</td>\n      <td>7242</td>\n      <td>0</td>\n      <td>2170</td>\n      <td>1690</td>\n      <td>7639</td>\n      <td>23</td>\n      <td>63</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>770</td>\n      <td>10000</td>\n      <td>0</td>\n      <td>770</td>\n      <td>2720</td>\n      <td>8062</td>\n      <td>82</td>\n      <td>82</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1960</td>\n      <td>5000</td>\n      <td>0</td>\n      <td>1050</td>\n      <td>1360</td>\n      <td>5000</td>\n      <td>49</td>\n      <td>49</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1680</td>\n      <td>8080</td>\n      <td>0</td>\n      <td>1680</td>\n      <td>1800</td>\n      <td>7503</td>\n      <td>28</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 140 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "poly_feat_1 = df.drop(['price', 'bedrooms', 'bathrooms', 'floors', 'condition', 'grade', 'zipcode'], axis=1)\n",
    "X = pd.concat([poly_feat_1, df_dum], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 3.218e+10\nAverage bias: 3.052e+10\nAverage variance: 1.668e+09\nTraining R^2 Score:  0.8352\nTraining RMSE: 146745\nTesting R^2 Score:  0.815\nTesting RMSE: 167237\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "loss, bias, var = bias_variance_decomp(lr, X_train.values, y_train.values, X_test.values, y_test.values, loss='mse', random_seed=42)\n",
    "print('Average expected loss: %.3e' % loss)\n",
    "print('Average bias: %.3e' bias)\n",
    "print('Average variance: %.3e' % var)\n",
    "y_pred_train_lr = lr.predict(X_train)\n",
    "y_pred_test_lr = lr.predict(X_test)\n",
    "train_test_metrics(y_train, y_test, y_pred_train_lr, y_pred_test_lr)\n"
   ]
  },
  {
   "source": [
    "# Degree-2 Polynomial Features Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sqft_living  sqft_lot  waterfront  sqft_above  sqft_living15  sqft_lot15  \\\n",
       "0       1180.0    5650.0         0.0      1180.0         1340.0      5650.0   \n",
       "1       2570.0    7242.0         0.0      2170.0         1690.0      7639.0   \n",
       "2        770.0   10000.0         0.0       770.0         2720.0      8062.0   \n",
       "3       1960.0    5000.0         0.0      1050.0         1360.0      5000.0   \n",
       "4       1680.0    8080.0         0.0      1680.0         1800.0      7503.0   \n",
       "\n",
       "   sale_age   age  renovated  basement  ...  zip_98146  zip_98148  zip_98155  \\\n",
       "0      59.0  59.0        0.0       0.0  ...          0          0          0   \n",
       "1      23.0  63.0        1.0       1.0  ...          0          0          0   \n",
       "2      82.0  82.0        0.0       0.0  ...          0          0          0   \n",
       "3      49.0  49.0        0.0       1.0  ...          0          0          0   \n",
       "4      28.0  28.0        0.0       0.0  ...          0          0          0   \n",
       "\n",
       "   zip_98166  zip_98168  zip_98177  zip_98178  zip_98188  zip_98198  zip_98199  \n",
       "0          0          0          0          1          0          0          0  \n",
       "1          0          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 206 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>waterfront</th>\n      <th>sqft_above</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n      <th>sale_age</th>\n      <th>age</th>\n      <th>renovated</th>\n      <th>basement</th>\n      <th>...</th>\n      <th>zip_98146</th>\n      <th>zip_98148</th>\n      <th>zip_98155</th>\n      <th>zip_98166</th>\n      <th>zip_98168</th>\n      <th>zip_98177</th>\n      <th>zip_98178</th>\n      <th>zip_98188</th>\n      <th>zip_98198</th>\n      <th>zip_98199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1180.0</td>\n      <td>5650.0</td>\n      <td>0.0</td>\n      <td>1180.0</td>\n      <td>1340.0</td>\n      <td>5650.0</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2570.0</td>\n      <td>7242.0</td>\n      <td>0.0</td>\n      <td>2170.0</td>\n      <td>1690.0</td>\n      <td>7639.0</td>\n      <td>23.0</td>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>770.0</td>\n      <td>10000.0</td>\n      <td>0.0</td>\n      <td>770.0</td>\n      <td>2720.0</td>\n      <td>8062.0</td>\n      <td>82.0</td>\n      <td>82.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1960.0</td>\n      <td>5000.0</td>\n      <td>0.0</td>\n      <td>1050.0</td>\n      <td>1360.0</td>\n      <td>5000.0</td>\n      <td>49.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1680.0</td>\n      <td>8080.0</td>\n      <td>0.0</td>\n      <td>1680.0</td>\n      <td>1800.0</td>\n      <td>7503.0</td>\n      <td>28.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 206 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Grab columns for polynominal and interaction features from the original dataframe without dummy variables\n",
    "poly_feat_2 = df.drop(['price', 'bedrooms', 'bathrooms', 'floors', 'condition', 'grade', 'zipcode'], axis=1)\n",
    "# Use PolynomialFeatures to create binomial and interaction features\n",
    "poly_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_data_2 = poly_2.fit_transform(poly_feat_2)\n",
    "poly_columns_2 = poly_2.get_feature_names(poly_feat_2.columns)\n",
    "df_poly_2 = pd.DataFrame(poly_data_2, columns=poly_columns_2)\n",
    "# Concatenating two dataframes together for input into linear regression model\n",
    "X_poly_2 = pd.concat([df_poly_2, df_dum], axis=1)\n",
    "X_poly_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 2.595e+10\nAverage bias: 2.460e+10\nAverage variance: 1.350e+09\nTraining R^2 Score:  0.8675\nTraining RMSE: 131554\nTesting R^2 Score:  0.8362\nTesting RMSE: 157363\n"
     ]
    }
   ],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_poly_2, y, random_state=42, test_size=0.2, shuffle=True)\n",
    "lr_2 = LinearRegression().fit(X_train_2, y_train_2)\n",
    "loss_2, bias_2, var_2 = bias_variance_decomp(lr_2, X_train_2.values, y_train_2.values, X_test_2.values, y_test_2.values, loss='mse', random_seed=42)\n",
    "print('Average expected loss: %.3e' % loss_2)\n",
    "print('Average bias: %.3e' bias_2)\n",
    "print('Average variance: %.3e' % var_2)\n",
    "y_pred_train_lr_2 = lr_2.predict(X_train_2)\n",
    "y_pred_test_lr_2 = lr_2.predict(X_test_2)\n",
    "train_test_metrics(y_train_2, y_test_2, y_pred_train_lr_2, y_pred_test_lr_2)"
   ]
  },
  {
   "source": [
    "# Degree-3 Polynomial Features Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sqft_living  sqft_lot  waterfront  sqft_above  sqft_living15  sqft_lot15  \\\n",
       "0       1180.0    5650.0         0.0      1180.0         1340.0      5650.0   \n",
       "1       2570.0    7242.0         0.0      2170.0         1690.0      7639.0   \n",
       "2        770.0   10000.0         0.0       770.0         2720.0      8062.0   \n",
       "3       1960.0    5000.0         0.0      1050.0         1360.0      5000.0   \n",
       "4       1680.0    8080.0         0.0      1680.0         1800.0      7503.0   \n",
       "\n",
       "   sale_age   age  renovated  basement  ...  zip_98146  zip_98148  zip_98155  \\\n",
       "0      59.0  59.0        0.0       0.0  ...          0          0          0   \n",
       "1      23.0  63.0        1.0       1.0  ...          0          0          0   \n",
       "2      82.0  82.0        0.0       0.0  ...          0          0          0   \n",
       "3      49.0  49.0        0.0       1.0  ...          0          0          0   \n",
       "4      28.0  28.0        0.0       0.0  ...          0          0          0   \n",
       "\n",
       "   zip_98166  zip_98168  zip_98177  zip_98178  zip_98188  zip_98198  zip_98199  \n",
       "0          0          0          0          1          0          0          0  \n",
       "1          0          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 492 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>waterfront</th>\n      <th>sqft_above</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n      <th>sale_age</th>\n      <th>age</th>\n      <th>renovated</th>\n      <th>basement</th>\n      <th>...</th>\n      <th>zip_98146</th>\n      <th>zip_98148</th>\n      <th>zip_98155</th>\n      <th>zip_98166</th>\n      <th>zip_98168</th>\n      <th>zip_98177</th>\n      <th>zip_98178</th>\n      <th>zip_98188</th>\n      <th>zip_98198</th>\n      <th>zip_98199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1180.0</td>\n      <td>5650.0</td>\n      <td>0.0</td>\n      <td>1180.0</td>\n      <td>1340.0</td>\n      <td>5650.0</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2570.0</td>\n      <td>7242.0</td>\n      <td>0.0</td>\n      <td>2170.0</td>\n      <td>1690.0</td>\n      <td>7639.0</td>\n      <td>23.0</td>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>770.0</td>\n      <td>10000.0</td>\n      <td>0.0</td>\n      <td>770.0</td>\n      <td>2720.0</td>\n      <td>8062.0</td>\n      <td>82.0</td>\n      <td>82.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1960.0</td>\n      <td>5000.0</td>\n      <td>0.0</td>\n      <td>1050.0</td>\n      <td>1360.0</td>\n      <td>5000.0</td>\n      <td>49.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1680.0</td>\n      <td>8080.0</td>\n      <td>0.0</td>\n      <td>1680.0</td>\n      <td>1800.0</td>\n      <td>7503.0</td>\n      <td>28.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 492 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "poly_feat_3 = df.drop(['price', 'bedrooms', 'bathrooms', 'floors', 'condition', 'grade', 'zipcode'], axis=1)\n",
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly_data_3 = poly_3.fit_transform(poly_feat_3)\n",
    "poly_columns_3 = poly_3.get_feature_names(poly_feat_3.columns)\n",
    "df_poly_3 = pd.DataFrame(poly_data_3, columns=poly_columns_3)\n",
    "X_poly_3 = pd.concat([df_poly_3, df_dum], axis=1)\n",
    "X_poly_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 1.711e+11\nAverage bias: 5.695e+10\nAverage variance: 1.141e+11\nTraining R^2 Score:  0.1216\nTraining RMSE: 338762\nTesting R^2 Score:  0.5435\nTesting RMSE: 262698\n"
     ]
    }
   ],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_poly_3, y, random_state=42, test_size=0.2, shuffle=True)\n",
    "lr_3 = LinearRegression().fit(X_train_3, y_train_3)\n",
    "loss_3, bias_3, var_3 = bias_variance_decomp(lr_3, X_train_3.values, y_train_3.values, X_test_3.values, y_test_3.values, loss='mse', random_seed=42)\n",
    "print('Average expected loss: %.3e' % loss_3)\n",
    "print('Average bias: %.3e' bias_3)\n",
    "print('Average variance: %.3e' % var_3)\n",
    "y_pred_train_lr_3 = lr_3.predict(X_train_3)\n",
    "y_pred_test_lr_3 = lr_3.predict(X_test_3)\n",
    "train_test_metrics(y_train_3, y_test_3, y_pred_train_lr_3, y_pred_test_lr_3)"
   ]
  },
  {
   "source": [
    "# Degree-4 Polynomal Features Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sqft_living  sqft_lot  waterfront  sqft_above  sqft_living15  sqft_lot15  \\\n",
       "0       1180.0    5650.0         0.0      1180.0         1340.0      5650.0   \n",
       "1       2570.0    7242.0         0.0      2170.0         1690.0      7639.0   \n",
       "2        770.0   10000.0         0.0       770.0         2720.0      8062.0   \n",
       "3       1960.0    5000.0         0.0      1050.0         1360.0      5000.0   \n",
       "4       1680.0    8080.0         0.0      1680.0         1800.0      7503.0   \n",
       "\n",
       "   sale_age   age  renovated  basement  ...  zip_98146  zip_98148  zip_98155  \\\n",
       "0      59.0  59.0        0.0       0.0  ...          0          0          0   \n",
       "1      23.0  63.0        1.0       1.0  ...          0          0          0   \n",
       "2      82.0  82.0        0.0       0.0  ...          0          0          0   \n",
       "3      49.0  49.0        0.0       1.0  ...          0          0          0   \n",
       "4      28.0  28.0        0.0       0.0  ...          0          0          0   \n",
       "\n",
       "   zip_98166  zip_98168  zip_98177  zip_98178  zip_98188  zip_98198  zip_98199  \n",
       "0          0          0          0          1          0          0          0  \n",
       "1          0          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 1493 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>waterfront</th>\n      <th>sqft_above</th>\n      <th>sqft_living15</th>\n      <th>sqft_lot15</th>\n      <th>sale_age</th>\n      <th>age</th>\n      <th>renovated</th>\n      <th>basement</th>\n      <th>...</th>\n      <th>zip_98146</th>\n      <th>zip_98148</th>\n      <th>zip_98155</th>\n      <th>zip_98166</th>\n      <th>zip_98168</th>\n      <th>zip_98177</th>\n      <th>zip_98178</th>\n      <th>zip_98188</th>\n      <th>zip_98198</th>\n      <th>zip_98199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1180.0</td>\n      <td>5650.0</td>\n      <td>0.0</td>\n      <td>1180.0</td>\n      <td>1340.0</td>\n      <td>5650.0</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2570.0</td>\n      <td>7242.0</td>\n      <td>0.0</td>\n      <td>2170.0</td>\n      <td>1690.0</td>\n      <td>7639.0</td>\n      <td>23.0</td>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>770.0</td>\n      <td>10000.0</td>\n      <td>0.0</td>\n      <td>770.0</td>\n      <td>2720.0</td>\n      <td>8062.0</td>\n      <td>82.0</td>\n      <td>82.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1960.0</td>\n      <td>5000.0</td>\n      <td>0.0</td>\n      <td>1050.0</td>\n      <td>1360.0</td>\n      <td>5000.0</td>\n      <td>49.0</td>\n      <td>49.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1680.0</td>\n      <td>8080.0</td>\n      <td>0.0</td>\n      <td>1680.0</td>\n      <td>1800.0</td>\n      <td>7503.0</td>\n      <td>28.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1493 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "poly_feat_4 = df.drop(['price', 'bedrooms', 'bathrooms', 'floors', 'condition', 'grade', 'zipcode'], axis=1)\n",
    "poly_4 = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly_data_4 = poly_4.fit_transform(poly_feat_4)\n",
    "poly_columns_4 = poly_4.get_feature_names(poly_feat_4.columns)\n",
    "df_poly_4 = pd.DataFrame(poly_data_4, columns=poly_columns_4)\n",
    "X_poly_4 = pd.concat([df_poly_4, df_dum], axis=1)\n",
    "X_poly_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 3.801e+14\nAverage bias: 4.626e+12\nAverage variance: 3.755e+14\nTraining R^2 Score:  -230.2572\nTraining RMSE: 5496675\nTesting R^2 Score:  -8270.3959\nTesting RMSE: 35361595\n"
     ]
    }
   ],
   "source": [
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_poly_4, y, random_state=42, test_size=0.2, shuffle=True)\n",
    "lr_4 = LinearRegression().fit(X_train_4, y_train_4)\n",
    "loss_4, bias_4, var_4 = bias_variance_decomp(lr_4, X_train_4.values, y_train_4.values, X_test_4.values, y_test_4.values, loss='mse', random_seed=42)\n",
    "print('Average expected loss: %.3e' % loss_4)\n",
    "print('Average bias: %.3e' bias_4)\n",
    "print('Average variance: %.3e' % var_4)\n",
    "y_pred_train_lr_4 = lr_4.predict(X_train_4)\n",
    "y_pred_test_lr_4 = lr_4.predict(X_test_4)\n",
    "train_test_metrics(y_train_4, y_test_4, y_pred_train_lr_4, y_pred_test_lr_4)"
   ]
  },
  {
   "source": [
    "# "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, bias, var = bias_variance_decomp(lr, X_train.values, y_train.values, X_test.values, y_test.values, loss='mse', random_seed=42)\n",
    "loss_2, bias_2, var_2 = bias_variance_decomp(lr_2, X_train_2.values, y_train_2.values, X_test_2.values, y_test_2.values, loss='mse', random_seed=42)\n",
    "loss_3, bias_3, var_3 = bias_variance_decomp(lr_3, X_train_3.values, y_train_3.values, X_test_3.values, y_test_3.values, loss='mse', random_seed=42)\n",
    "loss_4, bias_4, var_4 = bias_variance_decomp(lr_4, X_train_4.values, y_train_4.values, X_test_4.values, y_test_4.values, loss='mse', random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['%.3e' % bias, '%.3e' % var, round(r2_score(y_train, y_pred_train_lr), 4), round(r2_score(y_test, y_pred_test_lr), 4), int(rmse(y_train, y_pred_train_lr)), int(rmse(y_test, y_pred_test_lr))],\n",
    "        ['%.3e' % bias_2, '%.3e' % var_2, round(r2_score(y_train_2, y_pred_train_lr_2), 4), round(r2_score(y_test_2, y_pred_test_lr_2), 4), int(rmse(y_train_2, y_pred_train_lr_2)), int(rmse(y_test_2, y_pred_test_lr_2))],\n",
    "        ['%.3e' % bias_3, '%.3e' % var_3, round(r2_score(y_train_3, y_pred_train_lr_3), 4), round(r2_score(y_test_3, y_pred_test_lr_3), 4), int(rmse(y_train_3, y_pred_train_lr_3)), int(rmse(y_test_3, y_pred_test_lr_3))],\n",
    "        ['%.3e' % bias_4, '%.3e' % var_4, round(r2_score(y_train_4, y_pred_train_lr_4), 4), round(r2_score(y_test_4, y_pred_test_lr_4), 4), int(rmse(y_train_4, y_pred_train_lr_4)), int(rmse(y_test_4, y_pred_test_lr_4))]]\n",
    "\n",
    "index = [\"Baseline\", \"Poly-2\", \"Poly-3\", \"Poly-4\"]\n",
    "columns = [\"Average Bias\", \"Average Variance\", \"Training R^2 Score\", \"Testing R^2 Score\", \"Training RMSE\", \"Testing RMSE\"]\n",
    "\n",
    "poly_feat_df = pd.DataFrame(data=data, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Average Bias Average Variance  Training R^2 Score  Testing R^2 Score  \\\n",
       "Baseline    3.052e+10        1.668e+09              0.8352             0.8150   \n",
       "Poly-2      2.460e+10        1.350e+09              0.8675             0.8362   \n",
       "Poly-3      5.695e+10        1.141e+11              0.1216             0.5435   \n",
       "Poly-4      4.626e+12        3.755e+14           -230.2572         -8270.3959   \n",
       "\n",
       "          Training RMSE  Testing RMSE  \n",
       "Baseline         146745        167237  \n",
       "Poly-2           131554        157363  \n",
       "Poly-3           338762        262698  \n",
       "Poly-4          5496675      35361595  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Average Bias</th>\n      <th>Average Variance</th>\n      <th>Training R^2 Score</th>\n      <th>Testing R^2 Score</th>\n      <th>Training RMSE</th>\n      <th>Testing RMSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Baseline</th>\n      <td>3.052e+10</td>\n      <td>1.668e+09</td>\n      <td>0.8352</td>\n      <td>0.8150</td>\n      <td>146745</td>\n      <td>167237</td>\n    </tr>\n    <tr>\n      <th>Poly-2</th>\n      <td>2.460e+10</td>\n      <td>1.350e+09</td>\n      <td>0.8675</td>\n      <td>0.8362</td>\n      <td>131554</td>\n      <td>157363</td>\n    </tr>\n    <tr>\n      <th>Poly-3</th>\n      <td>5.695e+10</td>\n      <td>1.141e+11</td>\n      <td>0.1216</td>\n      <td>0.5435</td>\n      <td>338762</td>\n      <td>262698</td>\n    </tr>\n    <tr>\n      <th>Poly-4</th>\n      <td>4.626e+12</td>\n      <td>3.755e+14</td>\n      <td>-230.2572</td>\n      <td>-8270.3959</td>\n      <td>5496675</td>\n      <td>35361595</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "poly_feat_df"
   ]
  },
  {
   "source": [
    "# Baseline Model 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "dum_feat = df[['bathrooms', 'condition', 'grade', 'zipcode']]\n",
    "dum_index = dum_feat.columns\n",
    "df_dum = pd.get_dummies(data = dum_feat, columns = dum_index, drop_first = True, prefix = ['bth', 'cnd', 'grd', 'zip'])\n",
    "poly_feat = df.drop(['price', 'bedrooms', 'bathrooms', 'floors', 'condition', 'grade', 'zipcode', 'sqft_lot15', 'sqft_above', 'sqft_lot'], axis = 1)\n",
    "poly = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "poly_data = poly.fit_transform(poly_feat)\n",
    "poly_columns = poly.get_feature_names(poly_feat.columns)\n",
    "df_poly = pd.DataFrame(poly_data, columns = poly_columns)\n",
    "X = pd.concat([df_poly, df_dum], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 2.831e+10\nAverage bias: 2.723e+10\nAverage variance: 1.080e+09\nTraining R^2 Score:  0.8673\nTraining RMSE: 131678\nTesting R^2 Score:  0.8086\nTesting RMSE: 170105\n"
     ]
    }
   ],
   "source": [
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X, y, random_state = 42, test_size = 0.2)\n",
    "lr_5 = LinearRegression().fit(X_train_5, y_train_5)\n",
    "y_pred_train_lr_5 = lr_5.predict(X_train_5)\n",
    "y_pred_test_lr_5 = lr_5.predict(X_test_5)\n",
    "loss_5, bias_5, var_5 = bias_variance_decomp(lr_5, X_train_5.values, y_train_5.values, X_test_5.values, y_test_5.values, loss='mse', random_seed=42)\n",
    "print('Average expected loss: %.3e' % loss_5)\n",
    "print('Average bias: %.3e' % bias_5)\n",
    "print('Average variance: %.3e' % var_5)\n",
    "train_test_metrics(y_train_5, y_test_5, y_pred_train_lr_5, y_pred_test_lr_5)\n"
   ]
  },
  {
   "source": [
    "# Ridge Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train_5)\n",
    "X_test_scaled = ss.transform(X_test_5)\n",
    "X_train_sc = pd.DataFrame(X_train_scaled, columns=X_train_5.columns)\n",
    "X_test_sc = pd.DataFrame(X_test_scaled, columns=X_test_5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 2.832e+10\nAverage bias: 2.725e+10\nAverage variance: 1.073e+09\nTraining R^2 Score:  0.8673\nTraining RMSE: 131679\nTesting R^2 Score:  0.8084\nTesting RMSE: 170176\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1).fit(X_train_sc, y_train_5)\n",
    "y_pred_train_ridge = ridge.predict(X_train_sc)\n",
    "y_pred_test_ridge = ridge.predict(X_test_sc)\n",
    "loss_6, bias_6, var_6 = bias_variance_decomp(ridge, X_train_5.values, y_train_5.values, X_test_5.values, y_test_5.values, loss='mse', random_seed=42)\n",
    "print('Average expected loss: %.3e' % loss_5)\n",
    "print('Average bias: %.3e' % bias_5)\n",
    "print('Average variance: %.3e' % var_5)\n",
    "get_bias_variance(ridge, X_train_sc, y_train_5, X_test_sc, y_test_5, 'mse')\n",
    "train_test_metrics(y_train_5, y_test_5, y_pred_train_ridge, y_pred_test_ridge)"
   ]
  },
  {
   "source": [
    "# Lasso Regression Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=1).fit(X_train_sc, y_train_2)\n",
    "y_pred_lasso_tr = lasso.predict(X_train_sc)\n",
    "y_pred_lasso_tt = lasso.predict(X_test_sc)\n",
    "get_bias_variance(lasso, X_train_sc, y_train_2, X_test_sc, y_test_2, 'mse')\n",
    "train_test_metrics(y_train_2, y_test_2, y_pred_lasso_tr, y_pred_lasso_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_tr_sc' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f2038e3652c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtr_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtr_rmse_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_tr_sc' is not defined"
     ]
    }
   ],
   "source": [
    "train_rmse_lasso = []\n",
    "test_rmse_lasso = []\n",
    "alphas_lasso = []\n",
    "\n",
    "for alpha in np.linspace(0, 1000, num=20):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_sc, y_train_2)\n",
    "    train_pred = lasso.predict(X_train_sc)\n",
    "    train_rmse_lasso.append(rmse(y_train_2, train_pred))\n",
    "    test_pred = lasso.predict(X_test_sc)\n",
    "    test_rmse_lasso.append(rmse(y_test_2, test_pred))\n",
    "    alphas_lasso.append(alpha)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alphas_lasso, train_rmse_lasso, label=\"Train\")\n",
    "ax.plot(alphas_lasso, test_rmse_lasso, label=\"Test\")\n",
    "ax.set_xlabel(\"Alpha\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "optimal_alpha = alphas_lasso[np.argmin(test_rmse_lasso)]\n",
    "ax.axvline(optimal_alpha, color=\"black\", linestyle=\"--\")\n",
    "print(f'Optimal Alpha Value: {int(optimal_alpha)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_tr_sc' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-7a1dd3adfa89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_lasso_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_lasso_tt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tt_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tt_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lasso_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lasso_tt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_tr_sc' is not defined"
     ]
    }
   ],
   "source": [
    "best_lasso = Lasso(alpha=600).fit(X_train_sc, y_train_2)\n",
    "y_pred_best_lasso_tr = best_lasso.predict(X_train_sc)\n",
    "y_pred_best_lasso_tt = best_lasso.predict(X_test_sc)\n",
    "get_bias_variance(best_lasso, X_train_sc, y_train_2, X_test_sc, y_test_2, 'mse')\n",
    "train_test_metrics(y_train_2, y_test_2, y_pred_best_lasso_tr, y_pred_best_lasso_tt)"
   ]
  },
  {
   "source": [
    "# Decision Tree Regressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average expected loss: 6.088e+10\nAverage bias: 3.170e+10\nAverage variance: 2.918e+10\nTraining R^2 Score:  0.9998\nTraining RMSE: 4839\nTesting R^2 Score:  0.585\nTesting RMSE: 250484\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(random_state=42).fit(X_train_5, y_train_5)\n",
    "y_pred_dt_train = dtr.predict(X_train_5) \n",
    "y_pred_dt_test = dtr.predict(X_test_5)\n",
    "get_bias_variance(dtr, X_train_5, y_train_5, X_test_5, y_test_5, 'mse')\n",
    "train_test_metrics(y_train_5, y_test_5, y_pred_dt_train, y_pred_dt_test)\n"
   ]
  },
  {
   "source": [
    "# Random Forest Regressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d823a4b652b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred_rf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred_rf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mget_bias_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_rf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_rf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5df2e6d47ed5>\u001b[0m in \u001b[0;36mget_bias_variance\u001b[0;34m(model, X_train, y_train, X_test, y_test, loss_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_bias_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mavg_expected_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias_variance_decomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average expected loss: %.3e'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mavg_expected_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average bias: %.3e'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mavg_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average variance: %.3e'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mavg_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/mlxtend/evaluate/bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[0;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             pred = estimator.fit(\n\u001b[0m\u001b[1;32m    110\u001b[0m                 X_boot, y_boot, **fit_params).predict(X_test)\n\u001b[1;32m    111\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \"\"\"\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, \n",
    "                           max_features=\"auto\", \n",
    "                           max_depth=100, \n",
    "                           min_samples_leaf=4, \n",
    "                           min_samples_split=10, \n",
    "                           random_state=1).fit(X_train_5, y_train_5)\n",
    "y_pred_rf_train = rf.predict(X_train_5)\n",
    "y_pred_rf_test = rf.predict(X_test_5)\n",
    "get_bias_variance(rf, X_train_5, y_train_5, X_test_5, y_test_5, 'mse')\n",
    "train_test_metrics(y_train_5, y_test_5, y_pred_rf_train, y_pred_rf_test)"
   ]
  },
  {
   "source": [
    "# DataFrame of Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[int(rmse(y_tr, y_tr_pred)), int(rmse(y_tt, y_tt_pred)), bias(y_tr, y_tr_pred), variance(y_tr_pred), bias(y_tt, y_tt_pred), variance(y_tt_pred)],\n",
    "        [int(rmse(y_tr_2, y_tr_pred_2)), int(rmse(y_tt_2, y_tt_pred_2)), bias(y_tr_2, y_tr_pred_2), variance(y_tr_pred_2), bias(y_tt_2, y_tt_pred_2), variance(y_tt_pred_2)],\n",
    "        [int(rmse(y_tr_3, y_tr_pred_3)), int(rmse(y_tt_3, y_tt_pred_3)), bias(y_tr_3, y_tr_pred_3), variance(y_tr_pred_3), bias(y_tt_3, y_tt_pred_3), variance(y_tt_pred_3)],\n",
    "        [int(rmse(y_tr_4, y_tr_pred_4)), int(rmse(y_tt_4, y_tt_pred_4)), bias(y_tr_4, y_tr_pred_4), variance(y_tr_pred_4), bias(y_tt_4, y_tt_pred_4), variance(y_tt_pred_4)],\n",
    "        [int(rmse(y_tr_5, y_tr_pred_5)), int(rmse(y_tt_5, y_tt_pred_5)), bias(y_tr_5, y_tr_pred_5), variance(y_tr_pred_5), bias(y_tt_5, y_tt_pred_5), variance(y_tt_pred_5)]]\n",
    "\n",
    "index = [\"Baseline 2\", \"Ridge\", \"Lasso\", \"Decision Tree\", \"Random Forest\"]\n",
    "\n",
    "columns = [\"Average Bias\", \"Average Variance\", \"\", \"Train Variance\", \"Test Bias\", \"Test Variance\"]\n",
    "\n",
    "poly_feat_df = pd.DataFrame(data=data, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}